\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Begriffe}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Definition Formel \& Algorithmen}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Specification of learning tasks}{1}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Machine Learning:}{1}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}LMS: Least Mean Squared}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Lineare Regression}{2}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Goodness of Modelfit, Regressionserror}{3}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Higher-Dimensional Feature Space}{3}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Concept Learning}{3}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Definitionen Text}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Supervised learning}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Unsupervised learning}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Reinforcement learning}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Feature Vektor}{4}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Ground Truth}{4}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Linear Models}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Overfitting}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Well- and Ill-posed problems}{6}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Regularization}{6}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Regularized Linear Regression}{6}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Neural Networks}{7}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Perception Learning}{7}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}PT Algorithm}{7}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Gradient Descent}{7}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Linear Regression + Squared Loss}{8}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}The Batch Gradient Descent (BGD) Algorithm}{8}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}The Incremental Gradient Descent IGD Algorithm}{9}{subsubsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Linear Regression + Squared Loss}{9}{subsubsection.5.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}Logistic Regression + Logistic Loss + Regularization}{9}{subsubsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Multilayer Perceptron}{10}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Linear Separability}{10}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Forward propagation}{11}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Backwards Propagation}{12}{subsubsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}IGD for Multilayer Perceptrons}{13}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Decision Trees}{13}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Splitting}{13}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Possible criteria for splitting of X(t)}{14}{subsubsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Decision Trees Definiton}{14}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}classification of some $\textbf  {x} \in X$ given a decision tree T}{15}{subsubsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Notations}{15}{subsubsection.6.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}DT-construct}{16}{subsubsection.6.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.4}DT-classify}{17}{subsubsection.6.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Evaluation of DT}{17}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}measuring Size}{17}{subsubsection.6.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2}Classification Error}{18}{subsubsection.6.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Impurity Functions}{18}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.1}Strict Impurity Function}{19}{subsubsection.6.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.2}Impurity of an Example Set}{19}{subsubsection.6.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.3}Impurity Reduction}{19}{subsubsection.6.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.4}Impurity Functions Based on the misclassification Rate}{19}{subsubsection.6.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Entropy}{20}{subsection.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.1}Conditional Entropy}{20}{subsubsection.6.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.2}Information Gain}{20}{subsubsection.6.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.3}Impurity Functions Based on Entropy}{21}{subsubsection.6.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.4}Impurity Functions Based on the Gini Index}{22}{subsubsection.6.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Decision Tree Algorithms}{22}{subsection.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.1}ID3 Algorithm}{22}{subsubsection.6.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.2}ID3 Beispiel}{24}{subsubsection.6.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.3}ID3 Inductive Bias}{25}{subsubsection.6.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.4}CART Algorithm}{25}{subsubsection.6.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Decision Tree Pruning}{26}{subsection.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.7.1}Overfitting (alias Overgrowing) Decision Trees}{27}{subsubsection.6.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.7.2}stopping instead of pruning}{27}{subsubsection.6.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8}Pruning}{27}{subsection.6.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.8.1}Pruning induced ordering}{28}{subsubsection.6.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.8.2}Reduced Error Pruning}{29}{subsubsection.6.8.2}\protected@file@percent }
\gdef \@abspage@last{29}
