\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Begriffe}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Definitionen}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Specification of learning tasks}{1}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Machine Learning:}{1}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Supervised learning}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Unsupervised learning}{2}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Reinforcement learning}{2}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Feature Vektor}{3}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Ground Truth}{3}{subsection.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Classification Approaches}{3}{subsection.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}generative approches}{3}{subsubsection.2.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}discriminative approaches}{3}{subsubsection.2.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Machine Learning Basics}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Lineare Regression}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}One Dimensional Feature Space}{3}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Higher Dimensional Feature Space}{4}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Goodness of Modelfit, Regressionserror}{4}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}LMS: Least Mean Squared}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Higher-Dimensional Feature Space}{5}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Concept Learning}{5}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Find-S}{5}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Candidate Elimination Algorithm}{7}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Version Space}{8}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Evaluating Effectivness}{8}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Generic Feature and Class Distributions}{8}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}True Error}{8}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Training Error}{9}{subsubsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4}Holdout Error}{9}{subsubsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.5}k-Fold Cross Validation}{9}{subsubsection.3.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.6}Comparing Model Variants}{10}{subsubsection.3.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Linear Models}{10}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Logistic Regression}{10}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Loss for Logistic Regression}{11}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Overfitting}{11}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Well- and Ill-posed problems}{12}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Regularization}{12}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Regularized Linear Regression}{12}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Neural Networks}{13}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Perception Learning}{13}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}PT Algorithm}{14}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Gradient Descent}{14}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Linear Regression + Squared Loss}{14}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}The Batch Gradient Descent (BGD) Algorithm}{15}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}The Incremental Gradient Descent IGD Algorithm}{16}{subsubsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Linear Regression + Squared Loss}{16}{subsubsection.5.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}Logistic Regression + Logistic Loss + Regularization}{16}{subsubsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Multilayer Perceptron}{16}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Linear Separability}{16}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Forward propagation}{18}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Backwards Propagation}{19}{subsubsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}IGD for Multilayer Perceptrons}{20}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Decision Trees}{20}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Splitting}{20}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Possible criteria for splitting of X(t)}{21}{subsubsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Decision Trees Definiton}{22}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}classification of some $\textbf  {x} \in X$ given a decision tree T}{22}{subsubsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Notations}{23}{subsubsection.6.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}DT-construct}{24}{subsubsection.6.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.4}DT-classify}{25}{subsubsection.6.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Evaluation of DT}{25}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}measuring Size}{25}{subsubsection.6.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2}Classification Error}{26}{subsubsection.6.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Impurity Functions}{26}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.1}Strict Impurity Function}{27}{subsubsection.6.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.2}Impurity of an Example Set}{27}{subsubsection.6.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.3}Impurity Reduction}{27}{subsubsection.6.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.4}Impurity Functions Based on the misclassification Rate}{27}{subsubsection.6.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Entropy}{28}{subsection.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.1}Conditional Entropy}{28}{subsubsection.6.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.2}Information Gain}{28}{subsubsection.6.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.3}Impurity Functions Based on Entropy}{29}{subsubsection.6.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.4}Impurity Functions Based on the Gini Index}{30}{subsubsection.6.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Decision Tree Algorithms}{30}{subsection.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.1}ID3 Algorithm}{30}{subsubsection.6.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.2}ID3 Beispiel}{32}{subsubsection.6.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.3}ID3 Inductive Bias}{33}{subsubsection.6.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.4}CART Algorithm}{33}{subsubsection.6.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Decision Tree Pruning}{34}{subsection.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.7.1}Overfitting (alias Overgrowing) Decision Trees}{35}{subsubsection.6.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.7.2}stopping instead of pruning}{35}{subsubsection.6.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8}Pruning}{35}{subsection.6.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.8.1}Pruning induced ordering}{36}{subsubsection.6.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.8.2}Reduced Error Pruning}{37}{subsubsection.6.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Statistical Learning}{37}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Probability Basics}{37}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Bayes Classification}{38}{subsection.7.2}\protected@file@percent }
\gdef \@abspage@last{38}
